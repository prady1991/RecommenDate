#!/usr/bin/env python
# -*- coding: utf-8 -*-
import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD, NMF
from sklearn.metrics.pairwise import cosine_similarity
import joblib
import pickle
import os
from math import sqrt
from RecommenDate.data import get_model, get_clean_data,download_model,download_vectoriser
from RecommenDate.similarity import similarity,get_topic,matching_topics,similarity_mean
from RecommenDate.model import Model


BUCKET_NAME = "recommendate-lewagon"
BUCKET_DATA_PATH = "okcupid_profiles.csv"
BUCKET_DATACLEAN_PATH = "clean_data.csv"
# model_download=download_model( bucket=BUCKET_NAME, rm=True)
# model_vectorizer_download=download_vectoriser(bucket= BUCKET_NAME,rm=True)
data = get_clean_data()
decompose_list=[]
components_list=[]


for i in range(10):
    model_vectorizer = get_model(f"models/vectorizer{i}.joblib")
    model=get_model(f"models/essay{i}.pkl")
    model_fit=Model(data[f'essay{i}_cleaned'],model_vectorizer,model)
    data_vectorized,vocab=model_fit.vectorizer()
    decompose,components,svd_explained=model_fit.decomposition_svd(n_components=500)
    decompose_list.append(decompose)
    components_list.append(components)
df_sim=similarity_mean(decompose_list,500,index=3)
print(df_sim)
