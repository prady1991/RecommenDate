{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd83e17f",
   "metadata": {},
   "source": [
    "### Import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a4a26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords \n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize \n",
    "import re\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155821f1",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e96f2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d04f455",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../raw_data/okcupid_profiles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e70438e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>you feel so inclined.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>66.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     status sex orientation       body_type               diet  \\\n",
       "0   22     single   m    straight  a little extra  strictly anything   \n",
       "1   35     single   m    straight         average       mostly other   \n",
       "2   38  available   m    straight            thin           anything   \n",
       "3   23     single   m    straight            thin         vegetarian   \n",
       "4   29     single   m    straight        athletic                NaN   \n",
       "\n",
       "     drinks      drugs                          education  \\\n",
       "0  socially      never      working on college/university   \n",
       "1     often  sometimes              working on space camp   \n",
       "2  socially        NaN     graduated from masters program   \n",
       "3  socially        NaN      working on college/university   \n",
       "4  socially      never  graduated from college/university   \n",
       "\n",
       "             ethnicity  height  income                          job  \\\n",
       "0         asian, white    75.0      -1               transportation   \n",
       "1                white    70.0   80000         hospitality / travel   \n",
       "2                  NaN    68.0      -1                          NaN   \n",
       "3                white    71.0   20000                      student   \n",
       "4  asian, black, other    66.0      -1  artistic / musical / writer   \n",
       "\n",
       "        last_online                         location  \\\n",
       "0  2012-06-28-20-30  south san francisco, california   \n",
       "1  2012-06-29-21-41              oakland, california   \n",
       "2  2012-06-27-09-10        san francisco, california   \n",
       "3  2012-06-28-14-22             berkeley, california   \n",
       "4  2012-06-27-21-26        san francisco, california   \n",
       "\n",
       "                                offspring                       pets  \\\n",
       "0  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "1  doesn't have kids, but might want them  likes dogs and likes cats   \n",
       "2                                     NaN                   has cats   \n",
       "3                       doesn't want kids                 likes cats   \n",
       "4                                     NaN  likes dogs and likes cats   \n",
       "\n",
       "                                   religion  \\\n",
       "0     agnosticism and very serious about it   \n",
       "1  agnosticism but not too serious about it   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks  \\\n",
       "0                                            english   \n",
       "1  english (fluently), spanish (poorly), french (...   \n",
       "2                               english, french, c++   \n",
       "3                           english, german (poorly)   \n",
       "4                                            english   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:  i would love to think that i was so...   \n",
       "1  i am a chef: this is what that means. 1. i am ...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh. ranting about a good salt...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at: http://bagsbrown....   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "2  my large jaw and large glasses are the physica...   \n",
       "3                  socially awkward but i do my best   \n",
       "4            i smile a lot and my inquisitive nature   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books: absurdistan, the republic, of mice and ...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "2  okay this is where the cultural matrix gets so...   \n",
       "3  bataille, celine, beckett. . . lynch, jarmusch...   \n",
       "4  music: bands, rappers, musicians at the moment...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0                  food. water. cell phone. shelter.   \n",
       "1  delicious porkness in all of its glories. my b...   \n",
       "2  movement conversation creation contemplation t...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "2                          NaN   \n",
       "3   cats and german philosophy   \n",
       "4                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "2  viewing. listening. dancing. talking. drinking...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "2  when i was five years old, i was known as \"the...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                              essay9  \n",
       "0  you want to be swept off your feet! you are ti...  \n",
       "1                                                NaN  \n",
       "2  you are bright, open, intense, silly, ironic, ...  \n",
       "3                              you feel so inclined.  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cce208",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.pets.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e66071",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pets=df.pets.fillna('likes dogs and likes cats')\n",
    "\n",
    "df.pets.replace(['likes dogs','likes dogs and has cats','has dogs','has dogs and likes cats','has dogs and has cats','has cats','likes cats'],'likes dogs and likes cats',inplace=True)\n",
    "\n",
    "df.pets.replace(['has dogs and dislikes cats','dislikes cats'],'likes dogs and dislikes cats',inplace=True)\n",
    "\n",
    "df.pets.replace(['dislikes dogs and has cats','dislikes dogs'],'dislikes dogs and likes cats',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38943bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc08ce",
   "metadata": {},
   "source": [
    "### My topics to clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d67a2ff",
   "metadata": {},
   "source": [
    "essay8- The most private thing I am willing to admit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1b81a8",
   "metadata": {},
   "source": [
    "essay9- You should message me if..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4035446",
   "metadata": {},
   "source": [
    "status, diet, ethnicity, last_online, religion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233b5f0",
   "metadata": {},
   "source": [
    "we have decided to remove last_online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1413b5",
   "metadata": {},
   "source": [
    "#### status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236a5492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.status.replace(\"unknown\",\"available\",inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271778c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['status'] = np.where(df['status'].str.contains('single'), 'available', df['status'])\n",
    "df = pd.concat([pd.get_dummies(df.status, prefix='status', prefix_sep='_'), df], axis = 1)\n",
    "\n",
    "df.status.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab779e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e7435",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['status'] = df['status'].map({'unknown': 'available', 'male': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a567a967",
   "metadata": {},
   "source": [
    "#### diet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43948a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diet.fillna(\"no restriction\", inplace=True)\n",
    "\n",
    "# create dummy variable: strict (1=strictly following a diet)\n",
    "df['strict'] = 0\n",
    "df.loc[df.diet.str.contains('strictly'), 'strict'] = 1\n",
    "df.loc[df.diet.str.len()==1, 'strict'] = 1\n",
    "\n",
    "# group diets\n",
    "df['diet'] = np.where(df['diet'].str.contains('strictly anything|mostly other|anything|mostly anything|strictly other|other'), 'no restriction', df['diet'])\n",
    "df.loc[df.diet=='no restriction', 'strict'] = 0\n",
    "df['diet'] = np.where(df['diet'].str.contains('mostly vegetarian|strictly vegan|strictly vegetarian|mostly vegan|vegan|vegetarian'), 'veggie', df['diet'])\n",
    "df['diet'] = np.where(df['diet'].str.contains('mostly kosher|strictly kosher|kosher'), 'kosher', df['diet'])\n",
    "df['diet'] = np.where(df['diet'].str.contains('mostly halal|strictly halal|halal'), 'halal', df['diet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794fcbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"status\"]==\"unknown\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bec8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"diet\"]==\"veggie\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5935faaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.diet.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df58c7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "174bf2ee",
   "metadata": {},
   "source": [
    "#### ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443b7d36",
   "metadata": {},
   "source": [
    "We can split ethnicity into 6 big groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba60510",
   "metadata": {},
   "source": [
    "white,asian,hispanic/latin,black,middle eastern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef783da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['eth_num'] = df.ethnicity.str.len()\n",
    "df[\"ethnicity2\"] = \"race\"\n",
    "df.loc[df.eth_num<2, \"ethnicity2\"] = df.ethnicity.str[0]\n",
    "df.loc[df.eth_num==2, \"ethnicity2\"] = \"biracial\"\n",
    "df.loc[df.eth_num>2, \"ethnicity2\"] = \"multiracial\"\n",
    "df.loc[df.eth_num>2, \"eth_num\"] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac2a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02a196",
   "metadata": {},
   "source": [
    "#### religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e05bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df.religion.isnull().sum()/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b71328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"religion\"] = df[\"religion\"].fillna('agnostic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d88384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.religion.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d9da61",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96764693",
   "metadata": {},
   "source": [
    "##### we will have to try different methods of fill NA in our model\n",
    "such as fill NA as agnostic or other\n",
    "\n",
    "#### we can also try to split the data in different ways such as\n",
    "shrink into 6 categories or \n",
    "split into categories and add column for intesity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7752af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.religion.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f255f07e",
   "metadata": {},
   "source": [
    "##### fill NA with agnostic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b1d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfagn = df.copy()\n",
    "\n",
    "dfagn[\"religion\"] = df[\"religion\"].fillna(\"agnosticism\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0d547b",
   "metadata": {},
   "source": [
    "##### fill NA with other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e264cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfother = df.copy()\n",
    "dfother[\"religion\"] = df[\"religion\"].fillna(\"other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809bcac8",
   "metadata": {},
   "source": [
    "##### add features for seriousness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea495051",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfagn['rel_scale'] = np.where(dfagn['religion'].str.contains(\"very serious\"), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd2e9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_religion_scale(df):\n",
    "    conditions = [\n",
    "        df['religion'].str.contains(\"very serious\"),\n",
    "        df['religion'].str.contains(\"somewhat serious\"),\n",
    "        df['religion'].str.contains(\"not too serious\"),\n",
    "        df['religion'].str.contains(\"laughing\")]\n",
    "    choices = ['very serious', 'somewhat serious', 'not too serious','laughing']\n",
    "    df['rel_scale'] = np.select(conditions, choices, default='normal')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b6ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.religion.fillna(\"other\", inplace=True)\n",
    "\n",
    "# create 1 variable: serious (1=yes, 0=neutral, -1=no)\n",
    "df[\"serious\"] = 0\n",
    "df.loc[df.religion.str.contains(\"very|somewhat\"), \"serious\"] = 1\n",
    "df.loc[df.religion.str.contains(\"laughing\"), \"serious\"] = -1\n",
    "df.religion = df.religion.str.split().str[0]\n",
    "# df.groupby(\"religion\")[\"serious\"].mean()\n",
    "\n",
    "# seriousness by religion\n",
    "plt.plot(df.groupby(\"religion\")[\"serious\"].mean(), marker='o', color=\"#5e3a98\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"how seriously does a user take religion?\")\n",
    "plt.ylabel(\"average seriousness\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717a37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfagn = create_religion_scale(dfagn)\n",
    "dfagn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba186594",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfother = create_religion_scale(dfother)\n",
    "\n",
    "dfother"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c98ac3",
   "metadata": {},
   "source": [
    "#### cleaning function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f7aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean (text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, ' ') # Remove Punctuation\n",
    "    lowercased = text.lower() # Lower Case\n",
    "    tokenized = word_tokenize(lowercased) # Tokenize\n",
    "    words_only = [word for word in tokenized if word.isalpha()] # Remove numbers\n",
    "    stop_words = set(stopwords.words('english')) # Make stopword list\n",
    "    without_stopwords = [word for word in words_only if not word in stop_words] # Remove Stop Words\n",
    "    lemma=WordNetLemmatizer() # Initiate Lemmatizer\n",
    "    lemmatized = [lemma.lemmatize(word) for word in without_stopwords] # Lemmatize\n",
    "    return lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a07f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['essay0']=df['essay8'].fillna('')\n",
    "df['essay1']=df['essay9'].fillna('')\n",
    "df['essay2']=df['essay8'].fillna('')\n",
    "df['essay3']=df['essay9'].fillna('')\n",
    "df['essay4']=df['essay8'].fillna('')\n",
    "df['essay5']=df['essay9'].fillna('')\n",
    "df['essay6']=df['essay8'].fillna('')\n",
    "df['essay7']=df['essay9'].fillna('')\n",
    "df['essay8']=df['essay8'].fillna('')\n",
    "df['essay9']=df['essay9'].fillna('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf50be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['essay0clean'] = df['essay0'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))\n",
    "df['essay1clean'] = df['essay1'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))\n",
    "df['essay2clean'] = df['essay2'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))\n",
    "df['essay3clean'] = df['essay3'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))\n",
    "df['essay4clean'] = df['essay4'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))\n",
    "df['essay5clean'] = df['essay5'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))\n",
    "df['essay6clean'] = df['essay6'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))\n",
    "df['essay7clean'] = df['essay7'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))\n",
    "df['essay8clean'] = df['essay8'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))\n",
    "df['essay9clean'] = df['essay9'].apply(lambda x: clean(x)).apply(lambda x:' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e897ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfessay = df[['essay0clean','essay1clean','essay2clean','essay3clean','essay4clean','essay5clean','essay6clean','essay7clean','essay8clean','essay9clean']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ae7461",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfessay.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813c3a0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dddc341",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b981c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_df=0.5,ngram_range=(3,3))\n",
    "\n",
    "data_vectorized = vectorizer.fit_transform(dfessay[\"essay0clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae7c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2,perplexity=40,random_state=42)\n",
    "tsne_essays = tsne.fit_transform(data_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(tsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489a446e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['essay8clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0daba436",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['essay8'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc8cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['essay9clean'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c229a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['essay9'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e88e600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "nb_dir = os.path.split(os.getcwd())[0]\n",
    "if nb_dir not in sys.path:\n",
    "    sys.path.append(nb_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7d04ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/rohito/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/rohito/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/rohito/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/rohito/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from RecommenDate import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6245ba3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = clean_data.clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ea1823",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "      <th>job</th>\n",
       "      <th>last_online</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "      <th>religion_info</th>\n",
       "      <th>strict</th>\n",
       "      <th>speaks_cleaned</th>\n",
       "      <th>primary_language</th>\n",
       "      <th>number_of_languages</th>\n",
       "      <th>essay0_cleaned</th>\n",
       "      <th>essay1_cleaned</th>\n",
       "      <th>essay2_cleaned</th>\n",
       "      <th>essay3_cleaned</th>\n",
       "      <th>essay4_cleaned</th>\n",
       "      <th>essay5_cleaned</th>\n",
       "      <th>essay6_cleaned</th>\n",
       "      <th>essay7_cleaned</th>\n",
       "      <th>essay8_cleaned</th>\n",
       "      <th>essay9_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>no restriction</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>75.0</td>\n",
       "      <td>104395</td>\n",
       "      <td>transportation</td>\n",
       "      <td>2012-06-28-20-30</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>0</td>\n",
       "      <td>[english]</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>would love think kind intellectual either dumb...</td>\n",
       "      <td>currently working international agent freight ...</td>\n",
       "      <td>making people laugh ranting good salting findi...</td>\n",
       "      <td>way look six foot half asian half caucasian mu...</td>\n",
       "      <td>book absurdistan republic mouse men book made ...</td>\n",
       "      <td>food water cell phone shelter</td>\n",
       "      <td>duality humorous thing</td>\n",
       "      <td>trying find someone hang anything except club</td>\n",
       "      <td>new california looking someone wisper secret</td>\n",
       "      <td>want swept foot tired norm want catch coffee b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>no restriction</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>70.0</td>\n",
       "      <td>80000</td>\n",
       "      <td>hospitality / travel</td>\n",
       "      <td>2012-06-29-21-41</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn't have kids, but might want them</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td></td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td></td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>0</td>\n",
       "      <td>[english, fluently, spanish, poorly, french, p...</td>\n",
       "      <td>english</td>\n",
       "      <td>4</td>\n",
       "      <td>chef mean workaholic love cook regardless whet...</td>\n",
       "      <td>dedicating everyday unbelievable badass</td>\n",
       "      <td>silly ridiculous amonts fun wherever smart as ...</td>\n",
       "      <td></td>\n",
       "      <td>die hard christopher moore fan really watch lo...</td>\n",
       "      <td>delicious porkness glory big as doughboy sinki...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>open share anything</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>available</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>no restriction</td>\n",
       "      <td>socially</td>\n",
       "      <td>rather not say</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>104395</td>\n",
       "      <td>other</td>\n",
       "      <td>2012-06-27-09-10</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>rather not say</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>okay this is where the cultural matrix gets so...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td></td>\n",
       "      <td>viewing. listening. dancing. talking. drinking...</td>\n",
       "      <td>when i was five years old, i was known as \"the...</td>\n",
       "      <td>you are bright, open, intense, silly, ironic, ...</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>0</td>\n",
       "      <td>[english, french, c]</td>\n",
       "      <td>english</td>\n",
       "      <td>3</td>\n",
       "      <td>ashamed much writing public text online dating...</td>\n",
       "      <td>make nerdy software musician artist experiment...</td>\n",
       "      <td>improvising different context alternating pres...</td>\n",
       "      <td>large jaw large glass physical thing people co...</td>\n",
       "      <td>okay cultural matrix get specific like crossha...</td>\n",
       "      <td>movement conversation creation contemplation t...</td>\n",
       "      <td></td>\n",
       "      <td>viewing listening dancing talking drinking per...</td>\n",
       "      <td>five year old known boogerman</td>\n",
       "      <td>bright open intense silly ironic critical cari...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>thin</td>\n",
       "      <td>veggie</td>\n",
       "      <td>socially</td>\n",
       "      <td>rather not say</td>\n",
       "      <td>NaN</td>\n",
       "      <td>white</td>\n",
       "      <td>71.0</td>\n",
       "      <td>20000</td>\n",
       "      <td>student</td>\n",
       "      <td>2012-06-28-14-22</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn't want kids</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>bataille, celine, beckett. . . lynch, jarmusch...</td>\n",
       "      <td></td>\n",
       "      <td>cats and german philosophy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>you feel so inclined.</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>0</td>\n",
       "      <td>[english, german, poorly]</td>\n",
       "      <td>english</td>\n",
       "      <td>2</td>\n",
       "      <td>work library go school</td>\n",
       "      <td>reading thing written old dead people</td>\n",
       "      <td>playing synthesizer organizing book according ...</td>\n",
       "      <td>socially awkward best</td>\n",
       "      <td>bataille celine beckett lynch jarmusch r w fas...</td>\n",
       "      <td></td>\n",
       "      <td>cat german philosophy</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>feel inclined</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>athletic</td>\n",
       "      <td>no restriction</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>NaN</td>\n",
       "      <td>asian, black, other</td>\n",
       "      <td>66.0</td>\n",
       "      <td>104395</td>\n",
       "      <td>artistic / musical / writer</td>\n",
       "      <td>2012-06-27-21-26</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>rather not say</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at: http://bagsbrown....</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>music: bands, rappers, musicians at the moment...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>agnosticism</td>\n",
       "      <td>0</td>\n",
       "      <td>[english]</td>\n",
       "      <td>english</td>\n",
       "      <td>1</td>\n",
       "      <td>hey going currently vague profile know come so...</td>\n",
       "      <td>work work work work play</td>\n",
       "      <td>creating imagery look http bagsbrown blogspot ...</td>\n",
       "      <td>smile lot inquisitive nature</td>\n",
       "      <td>music band rapper musician moment thee oh see ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     status sex orientation       body_type            diet    drinks  \\\n",
       "0   22     single   m    straight  a little extra  no restriction  socially   \n",
       "1   35     single   m    straight         average  no restriction     often   \n",
       "2   38  available   m    straight            thin  no restriction  socially   \n",
       "3   23     single   m    straight            thin          veggie  socially   \n",
       "4   29     single   m    straight        athletic  no restriction  socially   \n",
       "\n",
       "            drugs  education            ethnicity  height  income  \\\n",
       "0           never        NaN         asian, white    75.0  104395   \n",
       "1       sometimes        NaN                white    70.0   80000   \n",
       "2  rather not say        NaN                  NaN    68.0  104395   \n",
       "3  rather not say        NaN                white    71.0   20000   \n",
       "4           never        NaN  asian, black, other    66.0  104395   \n",
       "\n",
       "                           job       last_online  \\\n",
       "0               transportation  2012-06-28-20-30   \n",
       "1         hospitality / travel  2012-06-29-21-41   \n",
       "2                        other  2012-06-27-09-10   \n",
       "3                      student  2012-06-28-14-22   \n",
       "4  artistic / musical / writer  2012-06-27-21-26   \n",
       "\n",
       "                          location                               offspring  \\\n",
       "0  south san francisco, california  doesn't have kids, but might want them   \n",
       "1              oakland, california  doesn't have kids, but might want them   \n",
       "2        san francisco, california                          rather not say   \n",
       "3             berkeley, california                       doesn't want kids   \n",
       "4        san francisco, california                          rather not say   \n",
       "\n",
       "                        pets                                  religion  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   \n",
       "2  likes dogs and likes cats                               agnosticism   \n",
       "3  likes dogs and likes cats                               agnosticism   \n",
       "4  likes dogs and likes cats                               agnosticism   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks  \\\n",
       "0                                            english   \n",
       "1  english (fluently), spanish (poorly), french (...   \n",
       "2                               english, french, c++   \n",
       "3                           english, german (poorly)   \n",
       "4                                            english   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:  i would love to think that i was so...   \n",
       "1  i am a chef: this is what that means. 1. i am ...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh. ranting about a good salt...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at: http://bagsbrown....   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                      \n",
       "2  my large jaw and large glasses are the physica...   \n",
       "3                  socially awkward but i do my best   \n",
       "4            i smile a lot and my inquisitive nature   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books: absurdistan, the republic, of mice and ...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "2  okay this is where the cultural matrix gets so...   \n",
       "3  bataille, celine, beckett. . . lynch, jarmusch...   \n",
       "4  music: bands, rappers, musicians at the moment...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0                  food. water. cell phone. shelter.   \n",
       "1  delicious porkness in all of its glories. my b...   \n",
       "2  movement conversation creation contemplation t...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                                \n",
       "2                                \n",
       "3   cats and german philosophy   \n",
       "4                                \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                      \n",
       "2  viewing. listening. dancing. talking. drinking...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "2  when i was five years old, i was known as \"the...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                              essay9 religion_info  strict  \\\n",
       "0  you want to be swept off your feet! you are ti...   agnosticism       0   \n",
       "1                                                      agnosticism       0   \n",
       "2  you are bright, open, intense, silly, ironic, ...   agnosticism       0   \n",
       "3                              you feel so inclined.   agnosticism       0   \n",
       "4                                                      agnosticism       0   \n",
       "\n",
       "                                      speaks_cleaned primary_language  \\\n",
       "0                                          [english]          english   \n",
       "1  [english, fluently, spanish, poorly, french, p...          english   \n",
       "2                               [english, french, c]          english   \n",
       "3                          [english, german, poorly]          english   \n",
       "4                                          [english]          english   \n",
       "\n",
       "   number_of_languages                                     essay0_cleaned  \\\n",
       "0                    1  would love think kind intellectual either dumb...   \n",
       "1                    4  chef mean workaholic love cook regardless whet...   \n",
       "2                    3  ashamed much writing public text online dating...   \n",
       "3                    2                             work library go school   \n",
       "4                    1  hey going currently vague profile know come so...   \n",
       "\n",
       "                                      essay1_cleaned  \\\n",
       "0  currently working international agent freight ...   \n",
       "1            dedicating everyday unbelievable badass   \n",
       "2  make nerdy software musician artist experiment...   \n",
       "3              reading thing written old dead people   \n",
       "4                           work work work work play   \n",
       "\n",
       "                                      essay2_cleaned  \\\n",
       "0  making people laugh ranting good salting findi...   \n",
       "1  silly ridiculous amonts fun wherever smart as ...   \n",
       "2  improvising different context alternating pres...   \n",
       "3  playing synthesizer organizing book according ...   \n",
       "4  creating imagery look http bagsbrown blogspot ...   \n",
       "\n",
       "                                      essay3_cleaned  \\\n",
       "0  way look six foot half asian half caucasian mu...   \n",
       "1                                                      \n",
       "2  large jaw large glass physical thing people co...   \n",
       "3                              socially awkward best   \n",
       "4                       smile lot inquisitive nature   \n",
       "\n",
       "                                      essay4_cleaned  \\\n",
       "0  book absurdistan republic mouse men book made ...   \n",
       "1  die hard christopher moore fan really watch lo...   \n",
       "2  okay cultural matrix get specific like crossha...   \n",
       "3  bataille celine beckett lynch jarmusch r w fas...   \n",
       "4  music band rapper musician moment thee oh see ...   \n",
       "\n",
       "                                      essay5_cleaned          essay6_cleaned  \\\n",
       "0                      food water cell phone shelter  duality humorous thing   \n",
       "1  delicious porkness glory big as doughboy sinki...                           \n",
       "2  movement conversation creation contemplation t...                           \n",
       "3                                                      cat german philosophy   \n",
       "4                                                                              \n",
       "\n",
       "                                      essay7_cleaned  \\\n",
       "0      trying find someone hang anything except club   \n",
       "1                                                      \n",
       "2  viewing listening dancing talking drinking per...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                 essay8_cleaned  \\\n",
       "0  new california looking someone wisper secret   \n",
       "1                           open share anything   \n",
       "2                 five year old known boogerman   \n",
       "3                                                 \n",
       "4                                                 \n",
       "\n",
       "                                      essay9_cleaned  \n",
       "0  want swept foot tired norm want catch coffee b...  \n",
       "1                                                     \n",
       "2  bright open intense silly ironic critical cari...  \n",
       "3                                      feel inclined  \n",
       "4                                                     "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3cf803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Makefile     \u001b[0m\u001b[01;34mnotebooks\u001b[0m/  README.md      requirements.txt  setup.py\r\n",
      "MANIFEST.in  \u001b[01;34mraw_data\u001b[0m/   \u001b[01;34mRecommenDate\u001b[0m/  \u001b[01;34mscripts\u001b[0m/          \u001b[01;34mtests\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "ls .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a2c97bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path  \n",
    "filepath = Path('../raw_data/clean_data.csv')  \n",
    "filepath.parent.mkdir(parents=True, exist_ok=True)  \n",
    "clean_df.to_csv(filepath) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6ee20c6e0097167fdea31101eb44251aeb7bbb6545b9f813d82369e268ae541a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
